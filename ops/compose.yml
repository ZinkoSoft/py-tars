# ops/compose.yaml
# Usage:
#   docker compose -f ops/compose.yaml up --build
#
# This file reuses ONE generic Dockerfile (docker/app.Dockerfile) for all apps.
# Each service passes different build args (APP_PATH, APP_MODULE) to build its image.
#
# Repo assumptions (monorepo layout):
#   /apps/router, /apps/tts-worker, /apps/stt-worker
#   /packages/tars-core
#   /docker/app.Dockerfile  (this file references it)
#
# Notes:
# - The apps implement retry-on-connect to MQTT; strict health ordering isn't required.
# - If you provide console scripts in pyproject.toml, you can replace `command:` with them.

name: tars-stack

services:
  mqtt:
    image: eclipse-mosquitto:2
    container_name: tars-mqtt
    ports:
      - "1883:1883"
    # volumes:
    #   - ./mosquitto:/mosquitto   # optional: supply custom config/persistence
    # Simple TCP healthcheck (requires /bin/sh from mosquitto image)
    healthcheck:
      test: ["CMD-SHELL", "sh -c 'echo > /dev/tcp/127.0.0.1/1883'"]
      interval: 5s
      timeout: 3s
      retries: 10

  router:
    build:
      context: ..                      # root of the repo
      dockerfile: docker/app.Dockerfile
      args:
        PY_VERSION: "3.11"
        APP_PATH: apps/router
        CONTRACTS_PATH: packages/tars-core
        APP_MODULE: tars_router.app_main
    image: tars/router:dev
    container_name: tars-router
    environment:
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
    depends_on:
      mqtt:
        condition: service_healthy
    # If router defines a console script `tars-router`, you can use:
    # command: ["tars-router"]
    command: ["sh","-lc","python -m tars_router.app_main"]
    restart: unless-stopped

  tts:
    build:
      context: ..
      dockerfile: docker/app.Dockerfile
      args:
        PY_VERSION: "3.11"
        APP_PATH: apps/tts-worker
        CONTRACTS_PATH: packages/tars-core
        APP_MODULE: tars_tts_worker.app_main
    image: tars/tts:dev
    container_name: tars-tts
    environment:
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
    depends_on:
      mqtt:
        condition: service_healthy
    command: ["sh","-lc","python -m tars_tts_worker.app_main"]
    restart: unless-stopped
    # Example of mounting voices/models if needed
    # volumes:
    #   - ./assets/voices:/voices:ro

  stt:
    build:
      context: ..
      dockerfile: docker/app.Dockerfile
      args:
        PY_VERSION: "3.11"
        APP_PATH: apps/stt-worker
        CONTRACTS_PATH: packages/tars-core
        APP_MODULE: tars_stt_worker.app_main
    image: tars/stt:dev
    container_name: tars-stt
    environment:
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
    depends_on:
      mqtt:
        condition: service_healthy
    command: ["sh","-lc","python -m tars_stt_worker.app_main"]
    restart: unless-stopped
    # devices:
    #   - "/dev/snd"   # if capturing audio from host

  wake-activation:
    build:
      context: ..
      dockerfile: docker/app.Dockerfile
      args:
        PY_VERSION: "3.11"
        APP_PATH: apps/wake-activation
        CONTRACTS_PATH: packages/tars-core
        APP_MODULE: wake_activation
    image: tars/wake-activation:dev
    container_name: tars-wake-activation
    environment:
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      LOG_LEVEL: "INFO"
      WAKE_AUDIO_FANOUT: /tmp/tars/audio-fanout.sock
      WAKE_MODEL_PATH: /models/openwakeword/hey_tars.tflite
    depends_on:
      mqtt:
        condition: service_healthy
      stt:
        condition: service_started
    volumes:
      - ../models/openwakeword:/models/openwakeword:ro
      - wake-cache:/tmp/tars
    restart: unless-stopped

  ui-web:
    build:
      context: ..
      dockerfile: apps/ui-web/Dockerfile
    image: tars/ui-web:dev
    container_name: tars-ui-web
    environment:
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      HOST: 0.0.0.0
      PORT: "5010"
    depends_on:
      mqtt:
        condition: service_healthy
    restart: unless-stopped

  llm:
    build:
      context: ..
      dockerfile: apps/llm-worker/Dockerfile
    image: tars/llm:dev
    container_name: tars-llm
    environment:
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      LOG_LEVEL: "INFO"
      LLM_PROVIDER: openai
      LLM_MODEL: gpt-4o-mini
      LLM_MAX_TOKENS: "512"
      LLM_TEMPERATURE: "0.7"
    depends_on:
      mqtt:
        condition: service_healthy
    restart: unless-stopped

# Optional: define multiple network(s)
networks:
  default:
    name: tars-net
    driver: bridge

volumes:
  wake-cache:
    driver: local
