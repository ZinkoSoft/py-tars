# ops/compose.yaml
# Usage:
#   docker compose -f ops/compose.yaml up --build                    # CPU mode (default)
#   docker compose -f ops/compose.yml -f ops/compose.npu.yml up     # NPU mode (RK3588 devices)
#
# NPU Requirements:
#   - RK3588-based device (Orange Pi 5 Max, Rock 5B, etc.)
#   - NPU setup: bash scripts/setup-rknpu.sh
#   - Model conversion: python scripts/convert_tflite_to_rknn.py --input models/openwakeword/hey_tars.tflite --output models/openwakeword/hey_tars.rknn
#
# This file reuses ONE generic Dockerfile (docker/app.Dockerfile) for all apps.
# Each service passes different build args (APP_PATH, APP_MODULE) to build its image.
#
# Repo assumptions (monorepo layout):
#   /apps/router, /apps/tts-worker, /apps/stt-worker
#   /packages/tars-core
#   /docker/app.Dockerfile  (this file references it)
#
# Notes:
# - The apps implement retry-on-connect to MQTT; strict health ordering isn't required.
# - If you provide console scripts in pyproject.toml, you can replace `command:` with them.

name: tars-stack

services:
  mqtt:
    env_file: ../.env
    image: eclipse-mosquitto:2
    container_name: tars-mqtt
    ports:
      - "1883:1883"
    volumes:
      - ./mosquitto.conf:/mosquitto/config/mosquitto.conf:ro
      - ./mosquitto-data:/mosquitto/data
      - ./mosquitto-config:/mosquitto/config
      # volumes:
      #   - ./mosquitto:/mosquitto   # optional: supply custom config/persistence
    restart: unless-stopped
    
  router:
    build:
      context: ..                      # root of the repo
      dockerfile: docker/app.Dockerfile
      args:
        PY_VERSION: "3.11"
        APP_PATH: apps/router
        CONTRACTS_PATH: packages/tars-core
        APP_MODULE: main
    env_file: ../.env
    image: tars/router:dev
    container_name: tars-router
    environment:
      MQTT_URL: mqtt://mqtt:1883
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      ROUTER_LLM_TTS_STREAM: ${ROUTER_LLM_TTS_STREAM:-1}
      TOPIC_LLM_STREAM: ${TOPIC_LLM_STREAM:-llm/stream}
      TOPIC_LLM_RESPONSE: ${TOPIC_LLM_RESPONSE:-llm/response}
      TOPIC_LLM_CANCEL: ${TOPIC_LLM_CANCEL:-llm/cancel}
      TOPIC_TTS_SAY: ${TOPIC_TTS_SAY:-tts/say}
      ROUTER_STREAM_MIN_CHARS: ${STREAM_MIN_CHARS:-60}
      ROUTER_STREAM_MAX_CHARS: ${STREAM_MAX_CHARS:-240}
      ROUTER_STREAM_BOUNDARY_CHARS: ${STREAM_BOUNDARY_CHARS:-.!?;:}
      ROUTER_TTS_VOICE: ${ROUTER_TTS_VOICE:-/voices/TARS.onnx}
      PYTHONPATH: /workspace/apps/router
    volumes:
      - ..:/workspace:ro
    depends_on:
      mqtt:
        condition: service_started
    # If router defines a console script `tars-router`, you can use:
    # command: ["tars-router"]
    restart: unless-stopped

  tts:
    build:
      context: ..
      dockerfile: docker/specialized/tts-worker.Dockerfile
    image: tars/tts:dev
    container_name: tars-tts
    env_file: ../.env
    environment:
      MQTT_URL: mqtt://mqtt:1883
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      PIPER_VOICE: /voices/TARS.onnx
      PULSE_RUNTIME_PATH: /run/user/1000/pulse
      PULSE_SERVER: unix:/run/user/1000/pulse/native
      TTS_STREAMING: ${TTS_STREAMING:-0}
      TTS_PIPELINE: ${TTS_PIPELINE:-1}
      TTS_WAKE_CACHE_ENABLE: ${TTS_WAKE_CACHE_ENABLE:-1}
      TTS_WAKE_CACHE_DIR: ${TTS_WAKE_CACHE_DIR:-/data/tts-cache}
      TTS_WAKE_CACHE_MAX: ${TTS_WAKE_CACHE_MAX:-16}
      PYTHONPATH: /workspace/apps/tts-worker

    depends_on:
      mqtt:
        condition: service_started
    # Image entrypoint handles startup
    restart: unless-stopped
    # Example of mounting voices/models if needed
    volumes:
      - ../apps/tts-worker/voices:/voice-models:ro
      - /run/user/1000/pulse:/run/user/1000/pulse:ro
      - ../data/tts-cache:/data/tts-cache
      - ..:/workspace:ro

  stt:
    build:
      context: ..
      dockerfile: docker/specialized/stt-worker.Dockerfile
    image: tars/stt:dev
    container_name: tars-stt
    env_file: ../.env
    environment:
      # Broker URL assembled from global creds/host/port
      MQTT_URL: mqtt://mqtt:1883
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      # Whisper model and logging
      WHISPER_MODEL: ${WHISPER_MODEL:-small}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      # Backend selection and remote WS URL (if STT_BACKEND=ws)
      STT_BACKEND: ${STT_BACKEND:-whisper}
      WS_URL: ${WS_URL:-ws://127.0.0.1:9000/stt}
      PULSE_RUNTIME_PATH: /run/user/1000/pulse
      PULSE_SERVER: unix:/run/user/1000/pulse/native
      # Audio/VAD
      SILENCE_THRESHOLD_MS: ${SILENCE_THRESHOLD_MS:-600}
      CHUNK_DURATION_MS: ${CHUNK_DURATION_MS:-20}
      VAD_AGGRESSIVENESS: ${VAD_AGGRESSIVENESS:-3}
      SAMPLE_RATE: ${SAMPLE_RATE:-16000}
      AUDIO_DEVICE_NAME: ${AUDIO_DEVICE_NAME:-}
      AUDIO_FANOUT_PATH: ${WAKE_AUDIO_FANOUT:-/tmp/tars/audio-fanout.sock}
      FFT_PUBLISH: ${FFT_PUBLISH:-0}
      FFT_RATE_HZ: ${FFT_RATE_HZ:-12}
      FFT_BINS: ${FFT_BINS:-64}
      FFT_LOG_SCALE: ${FFT_LOG_SCALE:-1}
      FFT_WS_ENABLE: ${FFT_WS_ENABLE:-1}
      FFT_WS_HOST: ${FFT_WS_HOST:-0.0.0.0}
      FFT_WS_PORT: ${FFT_WS_PORT:-8765}
      FFT_WS_PATH: ${FFT_WS_PATH:-/fft}
      # Noise floor calibration
      NOISE_FLOOR_CALIB_SECS: ${NOISE_FLOOR_CALIB_SECS:-2.0}
      NOISE_FLOOR_CALIB_ENABLE: ${NOISE_FLOOR_CALIB_ENABLE:-1}
      NOISE_FLOOR_ADAPTIVE_ENABLE: ${NOISE_FLOOR_ADAPTIVE_ENABLE:-1}
      NOISE_FLOOR_THRESHOLD_MULTIPLIER: ${NOISE_FLOOR_THRESHOLD_MULTIPLIER:-3.0}
      NOISE_FLOOR_UPDATE_INTERVAL: ${NOISE_FLOOR_UPDATE_INTERVAL:-50}
      PYTHONPATH: /workspace/apps/stt-worker
    entrypoint: ["/bin/sh", "-c"]
    command: ["if [ -d /host-models ] && [ -n \"$(ls -A /host-models 2>/dev/null)\" ]; then echo 'Copying models from host...'; cp -r /host-models/* /app/models/ 2>/dev/null || true; fi; exec python /workspace/apps/stt-worker/main.py"]
    depends_on:
      mqtt:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "test -S /tmp/tars/audio-fanout.sock && python -c 'import socket; s=socket.socket(socket.AF_UNIX); s.connect(\"/tmp/tars/audio-fanout.sock\"); s.close()' || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 6
      start_period: 15s
    devices:
      - /dev/snd:/dev/snd
    volumes:
      - /run/user/1000/pulse:/run/user/1000/pulse:ro
      - ../models/whisper:/host-models
      - ../docker/asoundrc:/etc/asound.conf:ro
      - wake-cache:/tmp/tars
      - ..:/workspace:ro

  wake-activation:
    build:
      context: ..
      dockerfile: docker/specialized/wake-activation.Dockerfile
      args:
        PY_VERSION: "3.11"
        APP_PATH: apps/wake-activation
        CONTRACTS_PATH: packages/tars-core
        APP_MODULE: wake_activation
    image: tars/wake-activation:dev
    container_name: tars-wake-activation
    env_file: ../.env
    environment:
      MQTT_URL: mqtt://mqtt:1883
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      WAKE_AUDIO_FANOUT: ${WAKE_AUDIO_FANOUT:-/tmp/tars/audio-fanout.sock}
      WAKE_MODEL_PATH: ${WAKE_MODEL_PATH:-/models/openwakeword/hey_tars.tflite}
      # NPU acceleration settings (RK3588 devices)
      WAKE_USE_NPU: ${WAKE_USE_NPU:-0}
      WAKE_RKNN_MODEL_PATH: ${WAKE_RKNN_MODEL_PATH:-/models/openwakeword/hey_tars.rknn}
      WAKE_NPU_CORE_MASK: ${WAKE_NPU_CORE_MASK:-0}
      # Wake sensitivity configuration
      WAKE_DETECTION_THRESHOLD: ${WAKE_DETECTION_THRESHOLD:-0.35}
      WAKE_MIN_RETRIGGER_SEC: ${WAKE_MIN_RETRIGGER_SEC:-0.8}
      WAKE_SPEEX_NOISE_SUPPRESSION: ${WAKE_SPEEX_NOISE_SUPPRESSION:-1}
      WAKE_VAD_THRESHOLD: ${WAKE_VAD_THRESHOLD:-0.3}
      # Advanced sensitivity tuning
      WAKE_ENERGY_BOOST_FACTOR: ${WAKE_ENERGY_BOOST_FACTOR:-1.2}
      WAKE_LOW_ENERGY_THRESHOLD_FACTOR: ${WAKE_LOW_ENERGY_THRESHOLD_FACTOR:-0.7}
      WAKE_BACKGROUND_NOISE_SENSITIVITY: ${WAKE_BACKGROUND_NOISE_SENSITIVITY:-1}
      # STT health monitoring
      WAKE_WAIT_FOR_STT_HEALTH: ${WAKE_WAIT_FOR_STT_HEALTH:-1}
      WAKE_STT_HEALTH_TIMEOUT_SEC: ${WAKE_STT_HEALTH_TIMEOUT_SEC:-30}
      # NPU-specific environment
      RKNN_LOG_LEVEL: ${RKNN_LOG_LEVEL:-3}
      PYTHONPATH: /workspace/apps/wake-activation/src
    entrypoint: ["/bin/sh", "-c"]
    command: ["echo 'Wake activation: Waiting for STT service to stabilize...'; sleep 3; echo 'Wake activation: Starting wake word detection'; exec python -m wake_activation"]
    depends_on:
      mqtt:
        condition: service_started
      stt:
        condition: service_healthy
    volumes:
      - ../models/openwakeword:/models/openwakeword:ro
      - wake-cache:/tmp/tars
      - ..:/workspace:ro
    restart: unless-stopped

  ui-web:
    build:
      context: ..
      dockerfile: docker/specialized/ui-web.Dockerfile
      args:
        SERVICE_PATH: apps/ui-web
    image: tars/ui-web:dev
    container_name: tars-ui-web
    env_file: ../.env
    environment:
      MQTT_URL: mqtt://mqtt:1883
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      HOST: 0.0.0.0
      PORT: "5010"
    ports:
      - "5010:5010"
    depends_on:
      mqtt:
        condition: service_started
    restart: unless-stopped

  camera:
    build:
      context: ..
      dockerfile: docker/specialized/camera-service.Dockerfile
    image: tars/camera:dev
    container_name: tars-camera
    env_file: ../.env
    environment:
      MQTT_URL: mqtt://mqtt:1883
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      CAMERA_WIDTH: ${CAMERA_WIDTH:-640}
      CAMERA_HEIGHT: ${CAMERA_HEIGHT:-480}
      CAMERA_FPS: ${CAMERA_FPS:-10}
      CAMERA_QUALITY: ${CAMERA_QUALITY:-80}
      CAMERA_ROTATION: ${CAMERA_ROTATION:-0}
      CAMERA_MQTT_RATE: ${CAMERA_MQTT_RATE:-2}
      CAMERA_HTTP_HOST: 0.0.0.0
      CAMERA_HTTP_PORT: ${CAMERA_HTTP_PORT:-8080}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      PYTHONPATH: /workspace/apps/camera-service/src
    command: ["python", "-m", "camera_service"]
    ports:
      - "${CAMERA_HTTP_PORT:-8080}:${CAMERA_HTTP_PORT:-8080}"
    volumes:
      - ..:/workspace:ro
    depends_on:
      mqtt:
        condition: service_started
    restart: unless-stopped
    devices:
      - /dev/video0:/dev/video0
    privileged: true

  ui:
    build:
      context: ..
      dockerfile: docker/specialized/ui.Dockerfile
    image: tars/ui:dev
    container_name: tars-ui
    env_file: ../.env
    ipc: host  # Share IPC namespace for X11
    shm_size: "512m"     # (optional but nice)
    environment:
      MQTT_URL: mqtt://mqtt:1883
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      UI_CONFIG: /config/ui.toml
      DISPLAY: ${DISPLAY:-:1}
      SDL_VIDEODRIVER: ${SDL_VIDEODRIVER:-x11}
      SDL_VIDEO_X11_FORCE_EGL: "1"        # <- force EGL instead of GLX on X11
      SDL_HINT_OPENGL_ES_DRIVER: "1"      # <- hint SDL to prefer OpenGL ES driver
      SDL_OPENGL_ES_DRIVER: "1"           # <- older alias of the same hint
      XAUTHORITY: ${XAUTHORITY:-/tmp/.docker_xauth}
      FFT_WS_ENABLE: 1
      FFT_WS_HOST: 0.0.0.0
      FFT_WS_PORT: 8765
      FFT_WS_PATH: /fft
      # Disable MIT-SHM to avoid attach errors
      SDL_VIDEO_X11_XSHM: "0"
      # OpenGL environment variables
      MESA_LOADER_DRIVER_OVERRIDE: panfrost # <- prefer panfrost on RK3588
      LIBGL_ALWAYS_INDIRECT: "0"
      LIBGL_ALWAYS_SOFTWARE: "0"
      # Force software rendering until GPU driver is fixed
      UI_SOFTWARE_RENDERING: ${UI_SOFTWARE_RENDERING:-0}
      PYOPENGL_PLATFORM: egl # <- use EGL backend for PyOpenGL
      SDL_AUDIODRIVER: dummy
    depends_on:
      mqtt:
        condition: service_started
    volumes:
      - ../apps/ui/ui.toml:/config/ui.toml:ro
      - /tmp/.X11-unix:/tmp/.X11-unix:ro
      - /run/user/1000/gdm/Xauthority:${XAUTHORITY:-/tmp/.docker_xauth}:ro
      # GPU/DRI access for hardware-accelerated OpenGL
      - /dev/dri:/dev/dri:rw
    devices:
      # Grant access to GPU devices for OpenGL acceleration
      - /dev/dri:/dev/dri
    group_add:
      - "44"   # 44 on your host
      - "992"  # 992 on your host
    restart: unless-stopped

  llm:
    build:
      context: ..
      dockerfile: docker/specialized/llm-worker.Dockerfile
    image: tars/llm:dev
    container_name: tars-llm
    env_file: ../.env
    environment:
      MQTT_URL: mqtt://${MQTT_USER}:${MQTT_PASS}@mqtt:1883
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LLM_PROVIDER: ${LLM_PROVIDER:-openai}
      LLM_MODEL: ${LLM_MODEL:-gpt-4o-mini}
      LLM_MAX_TOKENS: ${LLM_MAX_TOKENS:-512}
      LLM_TEMPERATURE: ${LLM_TEMPERATURE:-0.7}
      LLM_LOG_LEVEL: ${LLM_LOG_LEVEL:-INFO}
      TOOL_CALLING_ENABLED: ${TOOL_CALLING_ENABLED:-false}
      OPENAI_RESPONSES_MODELS: ${OPENAI_RESPONSES_MODELS:-gpt-5*,gpt-5-mini,gpt-5-nano}
      TOPIC_TOOLS_REGISTRY: ${TOPIC_TOOLS_REGISTRY:-llm/tools/registry}
      TOPIC_TOOL_CALL_RESULT: ${TOPIC_TOOL_CALL_RESULT:-llm/tools/result}
      PYTHONPATH: /workspace/apps/llm-worker
    volumes:
      - ..:/workspace:ro
    depends_on:
      mqtt:
        condition: service_started
    restart: unless-stopped

  memory:
    build:
      context: ..
      dockerfile: docker/specialized/memory-worker.Dockerfile
      args:
        NPU_EMBEDDER_ENABLED: ${NPU_EMBEDDER_ENABLED:-0}
    image: tars/memory:dev
    container_name: tars-memory
    env_file: ../.env
    environment:
      MQTT_URL: mqtt://mqtt:1883
      MQTT_HOST: mqtt
      MQTT_PORT: "1883"
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      MEMORY_DIR: /data
      MEMORY_FILE: memory.pickle.gz
      CHARACTER_NAME: ${CHARACTER_NAME:-TARS}
      CHARACTER_DIR: /config/characters
      EMBED_MODEL: ${EMBED_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
      RAG_STRATEGY: ${RAG_STRATEGY:-hybrid}
      MEMORY_TOP_K: ${MEMORY_TOP_K:-5}
      # NPU embedder settings (when NPU_EMBEDDER_ENABLED=1)
      NPU_EMBEDDER_ENABLED: ${NPU_EMBEDDER_ENABLED:-0}
      RKNN_EMBEDDER_PATH: ${RKNN_EMBEDDER_PATH:-/data/model_cache/embedder/all-MiniLM-L6-v2.rknn}
      NPU_CORE_MASK: ${NPU_CORE_MASK:-0}
      NPU_FALLBACK_CPU: ${NPU_FALLBACK_CPU:-1}
      PYTHONPATH: /workspace/apps/memory-worker
    volumes:
      - ../data/memory:/data
      - ../data/model_cache:/data/model_cache
      - ../apps/voice/characters:/config/characters:ro
      - ..:/workspace:ro
      - /proc/device-tree/compatible:/proc/device-tree/compatible:ro
      - /lib/librknnrt.so:/usr/lib/aarch64-linux-gnu/librknnrt.so:ro
    devices:
      - /dev/dri/renderD129:/dev/dri/renderD129
    depends_on:
      mqtt:
        condition: service_started
    restart: unless-stopped
    
# Optional: define multiple network(s)
networks:
  default:
    name: tars-net
    driver: bridge

volumes:
  wake-cache:
    driver: local
