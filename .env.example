########################################
# Global / Broker
########################################
# Copy to .env and edit values
MQTT_USER=tars
MQTT_PASS=change_me
MQTT_HOST=127.0.0.1
MQTT_PORT=1883
# Full MQTT URL (alternative to separate host/port/user/pass)
MQTT_URL=mqtt://tars:change_me@127.0.0.1:1883

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

########################################
# STT Worker (apps/stt-worker)
########################################
# Whisper model: tiny, base, small, medium (small is a good default)
WHISPER_MODEL=small
# Backend: whisper | ws | openai
STT_BACKEND=whisper
# WS STT endpoint (used when STT_BACKEND=ws)
WS_URL=ws://127.0.0.1:9000/stt

# OpenAI-compatible STT (used when STT_BACKEND=openai)
OPENAI_API_KEY=
OPENAI_BASE_URL=https://api.openai.com/v1
# Common models: whisper-1, gpt-4o-transcribe, gpt-4o-mini-transcribe (provider-dependent)
OPENAI_STT_MODEL=whisper-1
OPENAI_TIMEOUT_S=30

# Audio & VAD
AUDIO_DEVICE_NAME=
AUDIO_FANOUT_PATH=/tmp/tars/audio-fanout.sock
AUDIO_FANOUT_RATE=16000
SAMPLE_RATE=16000
CHUNK_DURATION_MS=30
VAD_AGGRESSIVENESS=2
VAD_ENHANCED_ANALYSIS=1
SILENCE_THRESHOLD_MS=1000

# Half-duplex / publish cadence
POST_PUBLISH_COOLDOWN_MS=400
UNMUTE_GUARD_MS=1000
WAKE_EVENT_FALLBACK_DELAY_MS=250
WAKE_EVENT_FALLBACK_TTL_MS=3500

# Echo suppression
ECHO_SUPPRESS_MATCH=1

# TTS mute window estimation (for avoiding self-echo)
TTS_BASE_MUTE_MS=1200
TTS_PER_CHAR_MS=45
TTS_MAX_MUTE_MS=12000

# Noise floor and quality gates
NOISE_MIN_DURATION_MS=400
NOISE_MIN_RMS=180
NOISE_FLOOR_INIT=180
NOISE_FLOOR_ALPHA=0.05
NOISE_GATE_OFFSET=1.5
NOISE_MIN_ALPHA_RATIO=0.55
NOISE_MIN_LENGTH=3
NOISE_MAX_PUNCT_RATIO=0.35

# Noise floor calibration and adaptive settings
NOISE_FLOOR_CALIB_SECS=2.0
NOISE_FLOOR_CALIB_ENABLE=1
NOISE_FLOOR_ADAPTIVE_ENABLE=1
NOISE_FLOOR_THRESHOLD_MULTIPLIER=3.0
NOISE_FLOOR_UPDATE_INTERVAL=50

# Extend dictionary for suppression (comma-separated). Useful for domain terms.
COMMON_WORDS_EXTRA=

# Cough/polite-phrase guardrails
COUGH_ACTIVE_MIN_RATIO=0.25
COUGH_MIN_DURATION_MS=600
COUGH_SUSPICIOUS_PHRASES=thank you,hello,okay,hi
COUGH_MIN_SYLLABLES=2

# Whisper metrics gates
NO_SPEECH_MAX=0.60
AVG_LOGPROB_MIN=-1.20
DICT_MATCH_MIN_RATIO=0.40
REPEAT_COOLDOWN_SEC=8

# Streaming partials
STREAMING_PARTIALS=1
PARTIAL_INTERVAL_MS=600
PARTIAL_MIN_DURATION_MS=500
PARTIAL_MIN_CHARS=4
PARTIAL_MIN_NEW_CHARS=2
PARTIAL_ALPHA_RATIO_MIN=0.5

# Server-side tail window (also used in server/stt-ws)
TAIL_WINDOW_SEC=6.0

# FFT publishing for UI
FFT_PUBLISH=1
FFT_TOPIC=stt/audio_fft
FFT_RATE_HZ=12
FFT_BINS=64
FFT_LOG_SCALE=1
FFT_WS_ENABLE=0
FFT_WS_HOST=0.0.0.0
FFT_WS_PORT=8765
FFT_WS_PATH=/fft

# Optional audio preprocessing (FFmpeg) to trim silence, denoise, and normalize before STT
# Enable to improve transcription robustness on noisy inputs. Default is disabled.
PREPROCESS_ENABLE=0
# Skip preprocessing for very short clips (ms)
PREPROCESS_MIN_MS=600
# Per-utterance FFmpeg timeout (seconds)
PREPROCESS_TIMEOUT_S=6
# FFmpeg filter chain (advanced). Default below is conservative and widely compatible.
# silenceremove trims leading/trailing silence; afftdn lightly denoises; loudnorm normalizes level.
PREPROCESS_FILTERS=silenceremove=start_periods=1:start_silence=2:start_threshold=-35dB:detection=peak,afftdn=nf=-25,loudnorm=I=-18:TP=-2:LRA=11

# Optional suppression quality upgrades (off by default)
SUPPRESS_USE_SYLLAPY=0
SUPPRESS_USE_RAPIDFUZZ=0
ECHO_FUZZ_MIN_RATIO=0.85

########################################
# Wake Activation (apps/wake-activation)
########################################
# Unix socket where the STT worker publishes raw PCM frames for wake detection.
WAKE_AUDIO_FANOUT=/tmp/tars/audio-fanout.sock
# OpenWakeWord model path inside the container (copied/mounted at build time).
WAKE_MODEL_PATH=/models/openwakeword/hey_tars.tflite
# RKNN model path for NPU acceleration (RK3588/Orange Pi 5 Max)
WAKE_RKNN_MODEL_PATH=/models/openwakeword/hey_tars.rknn
# Detection tuning
WAKE_DETECTION_THRESHOLD=0.55
WAKE_MIN_RETRIGGER_SEC=1.0
WAKE_DETECTION_WINDOW_MS=750
# Interrupt/cancel handling windows
WAKE_INTERRUPT_WINDOW_SEC=2.5
WAKE_IDLE_TIMEOUT_SEC=3.0

# NPU acceleration settings (RK3588/Orange Pi 5 Max)
WAKE_USE_NPU=0
WAKE_NPU_CORE_MASK=0

# Audio processing and sensitivity
WAKE_SPEEX_NOISE_SUPPRESSION=0
WAKE_VAD_THRESHOLD=0.0
WAKE_ENERGY_BOOST_FACTOR=1.0
WAKE_LOW_ENERGY_THRESHOLD_FACTOR=0.8
WAKE_BACKGROUND_NOISE_SENSITIVITY=0

# Health monitoring and dependencies
WAKE_HEALTH_INTERVAL_SEC=15
WAKE_STT_HEALTH_TOPIC=system/health/stt
WAKE_WAIT_FOR_STT_HEALTH=1
WAKE_STT_HEALTH_TIMEOUT_SEC=30

# MQTT topics for wake activation
WAKE_HEALTH_TOPIC=wake/health
WAKE_EVENT_TOPIC=wake/event
WAKE_MIC_TOPIC=wake/mic
WAKE_TTS_TOPIC=tts/control
WAKE_TTS_STATUS_TOPIC=tts/status
WAKE_STT_FINAL_TOPIC=stt/final

########################################
# Router (apps/router)
########################################
# Optional profile tag (not used in code; for your own process labelling)
PROFILE=offline_fast
# Speak a startup message when STT and TTS are both ready
ONLINE_ANNOUNCE=1
ONLINE_ANNOUNCE_TEXT=System online.

# Wake word + live mode (all processed locally)
# Comma/pipe separated wake phrases (case-insensitive). Example: hey tars|ok tars
ROUTER_WAKE_PHRASES=hey tars
# Seconds after a wake word to keep listening for a follow-up request
ROUTER_WAKE_WINDOW_SEC=8
# Enable/disable spoken wake acknowledgements (1=on, 0=off)
ROUTER_WAKE_ACK_ENABLED=1
# Short acknowledgement when the wake word is detected (blank to use choices below)
ROUTER_WAKE_ACK_TEXT=Yes?
# Pipe-separated list of witty wake acknowledgements (blank = built-in defaults)
ROUTER_WAKE_ACK_CHOICES=Hmm?|Huh?|Yes?
# Speaking style for wake acknowledgements (piper voice style tag)
ROUTER_WAKE_ACK_STYLE=friendly
# Optional follow-up prompt after the wake ack (blank to disable)
ROUTER_WAKE_REPROMPT_TEXT=
# Optional interruption/resume/cancel/timeout messages
ROUTER_WAKE_INTERRUPT_TEXT=
ROUTER_WAKE_RESUME_TEXT=
ROUTER_WAKE_CANCEL_TEXT=
ROUTER_WAKE_TIMEOUT_TEXT=

# Live mode configuration
# Start in live mode (routes every utterance without wake word)
ROUTER_LIVE_MODE_DEFAULT=0
# Control phrases to toggle live mode (case-insensitive)
ROUTER_LIVE_MODE_ENTER_PHRASE=start live mode
ROUTER_LIVE_MODE_EXIT_PHRASE=stop live mode
# Spoken confirmations for live mode toggles / state hints
ROUTER_LIVE_MODE_ENTER_ACK=Live mode enabled.
ROUTER_LIVE_MODE_EXIT_ACK=Live mode disabled.
ROUTER_LIVE_MODE_ACTIVE_HINT=Live mode is already active.
ROUTER_LIVE_MODE_INACTIVE_HINT=Live mode is already off.

# Router LLM->TTS streaming bridge
ROUTER_LLM_TTS_STREAM=1
# Streaming chunk settings
ROUTER_STREAM_MIN_CHARS=60
ROUTER_STREAM_MAX_CHARS=240
ROUTER_STREAM_BOUNDARY_CHARS=.!?;:
ROUTER_STREAM_BOUNDARY_ONLY=1
ROUTER_STREAM_HARD_MAX_CHARS=2000

# Advanced router processing settings
ROUTER_QUEUE_MAXSIZE=256
ROUTER_QUEUE_OVERFLOW=drop_oldest
ROUTER_HANDLER_TIMEOUT=30.0

# Router MQTT topic overrides (use defaults if not specified)
TOPIC_HEALTH_TTS=system/health/tts
TOPIC_HEALTH_STT=system/health/stt
TOPIC_HEALTH_ROUTER=system/health/router
TOPIC_STT_FINAL=stt/final
TOPIC_TTS_SAY=tts/say
TOPIC_TTS_STATUS=tts/status
TOPIC_LLM_REQUEST=llm/request
TOPIC_LLM_RESPONSE=llm/response
TOPIC_LLM_STREAM=llm/stream
TOPIC_LLM_CANCEL=llm/cancel
TOPIC_WAKE_EVENT=wake/event
# Router TTS voice (alternative to PIPER_VOICE)
ROUTER_TTS_VOICE=piper/en_US/amy

########################################
# TTS Worker (apps/tts-worker)
########################################



########################################
# Router (apps/router)
########################################
# Optional profile tag (not used in code; for your own process labelling)
PROFILE=offline_fast
# Speak a startup message when STT and TTS are both ready
ONLINE_ANNOUNCE=1
ONLINE_ANNOUNCE_TEXT=System online.

# Wake word + live mode (all processed locally)
# Comma/pipe separated wake phrases (case-insensitive). Example: hey tars|ok tars
ROUTER_WAKE_PHRASES=hey tars
# Seconds after a wake word to keep listening for a follow-up request
ROUTER_WAKE_WINDOW_SEC=8
# Enable/disable spoken wake acknowledgements (1=on, 0=off)
ROUTER_WAKE_ACK_ENABLED=1
# Short acknowledgement when the wake word is detected (blank to use choices below)
ROUTER_WAKE_ACK_TEXT=Yes?
# Pipe-separated list of witty wake acknowledgements (blank = built-in defaults)
ROUTER_WAKE_ACK_CHOICES=Hmm?|Huh?|Yes?
# Speaking style for wake acknowledgements (piper voice style tag)
ROUTER_WAKE_ACK_STYLE=friendly
# Optional follow-up prompt after the wake ack (blank to disable)
ROUTER_WAKE_REPROMPT_TEXT=
# Start in live mode (routes every utterance without wake word)
ROUTER_LIVE_MODE_DEFAULT=0
# Control phrases to toggle live mode (case-insensitive)
ROUTER_LIVE_MODE_ENTER_PHRASE=start live mode
ROUTER_LIVE_MODE_EXIT_PHRASE=stop live mode
# Spoken confirmations for live mode toggles / state hints
ROUTER_LIVE_MODE_ENTER_ACK=Live mode enabled.
ROUTER_LIVE_MODE_EXIT_ACK=Live mode disabled.
ROUTER_LIVE_MODE_ACTIVE_HINT=Live mode is already active.
ROUTER_LIVE_MODE_INACTIVE_HINT=Live mode is already off.

########################################
# TTS Worker (apps/tts-worker)
########################################
# Piper voice path inside container
PIPER_VOICE=/voices/TARS.onnx
# Streaming synthesis (attempt to reduce time-to-first-audio)
TTS_STREAMING=0
# Pipeline sentence-by-sentence
TTS_PIPELINE=1
# Number of concurrent synth workers when pipelining (only affects non-streaming)
TTS_CONCURRENCY=1
# Use simpleaudio for playback (in-process) instead of paplay/aplay
# Note: simpleaudio not installed by default; see REFACTOR_NOTES.md
TTS_SIMPLEAUDIO=0
# Aggregate consecutive tts/say messages that share an utt_id before speaking
TTS_AGGREGATE=1
# Debounce window (milliseconds) before flushing aggregated utterances
TTS_AGGREGATE_DEBOUNCE_MS=150
# When 1, aggregated text is rendered as a single WAV (streaming disabled for that flush)
TTS_AGGREGATE_SINGLE_WAV=1

# Cache common phrases (wake acks, system messages) as WAV files for instant playback
# Avoids redundant API calls to TTS providers for frequently repeated text
TTS_WAKE_CACHE_ENABLE=1
# Cache directory (relative to project root or absolute path)
TTS_WAKE_CACHE_DIR=data/tts-cache
# Maximum number of cached WAV files to keep
TTS_WAKE_CACHE_MAX=16
# Cached wake acknowledgment texts (populated from router config)
TTS_WAKE_ACK_TEXTS=
# Seconds to keep microphone unmuted after TTS speaking ends (for follow-up conversation)
TTS_RESPONSE_WINDOW_SEC=10.0

# External provider selection (optional)
# Choose text-to-speech engine:
#   piper      = local, offline (default)
#   elevenlabs = hosted ElevenLabs API (requires API key + voice id)
TTS_PROVIDER=piper

# ElevenLabs settings (used when TTS_PROVIDER=elevenlabs)
# Base API URL (usually leave default)
ELEVEN_API_BASE=https://api.elevenlabs.io/v1
# API key for ElevenLabs account (keep secret; do not commit real keys)
ELEVEN_API_KEY=
# Voice ID from your ElevenLabs dashboard (required)
ELEVEN_VOICE_ID=
# Model ID (see ElevenLabs docs). Good default is multilingual v2
ELEVEN_MODEL_ID=eleven_multilingual_v2
# Optimize streaming latency (0..3). Higher can reduce latency at cost of quality.
ELEVEN_OPTIMIZE_STREAMING=0

########################################
# UI Web (apps/ui-web)
########################################
UI_PARTIAL_TOPIC=stt/partial
UI_FINAL_TOPIC=stt/final
UI_TTS_TOPIC=tts/status
UI_AUDIO_TOPIC=stt/audio_fft

########################################
# Pygame UI (apps/ui)
########################################
# Optional: point to TOML config mounted into container
UI_CONFIG=/config/ui.toml
# Env overrides for UI config (optional)
UI_WIDTH=800
UI_HEIGHT=480
UI_FPS=30
UI_NUM_BARS=64
UI_FONT=Arial

########################################
# Camera Service (apps/camera-service)
########################################
# Enable/disable camera service (1=enabled, 0=disabled)
CAMERA_ENABLED=1
# Camera device index (0, 1, 2, etc. for /dev/video0, /dev/video1, etc.)
CAMERA_DEVICE_INDEX=0
# Resolution and framerate
CAMERA_WIDTH=640
CAMERA_HEIGHT=480
CAMERA_FPS=10
# JPEG compression quality (1-100)
CAMERA_QUALITY=80
# Rotation in degrees (0, 90, 180, 270)
CAMERA_ROTATION=0
# V4L2 capture timeout in milliseconds
CAMERA_TIMEOUT_MS=5000
# Retry attempts on capture failure
CAMERA_RETRY_ATTEMPTS=3
# Publish to MQTT every N seconds of frames (2 = every 2 seconds)
CAMERA_MQTT_RATE=2
# MQTT topic for frame publishing
CAMERA_FRAME_TOPIC=camera/frame
# HTTP streaming server settings
CAMERA_HTTP_HOST=0.0.0.0
CAMERA_HTTP_PORT=8080

########################################
# Memory Worker (apps/memory-worker)
########################################
# Storage
MEMORY_DIR=/data
MEMORY_FILE=memory.pickle.gz
RAG_STRATEGY=hybrid
MEMORY_TOP_K=5
# Embedding model (SentenceTransformer)
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Reranker (optional, adds ~1.5s latency but improves relevance)
# RERANK_MODEL=ms-marco-MiniLM-L-12-v2
# NPU acceleration for embeddings (3-4x faster on RK3588)
# When enabled, NPU models are automatically built during Docker build
# Set NPU_EMBEDDER_ENABLED=1 and rebuild: docker compose build memory
NPU_EMBEDDER_ENABLED=0
RKNN_EMBEDDER_PATH=/data/model_cache/embedder/all-MiniLM-L6-v2.rknn
NPU_CORE_MASK=0
NPU_FALLBACK_CPU=1
# MQTT topics
TOPIC_MEMORY_QUERY=memory/query
TOPIC_MEMORY_RESULTS=memory/results
# Memory health topic (retained)
TOPIC_MEMORY_HEALTH=system/health/memory
TOPIC_STT_FINAL=stt/final
TOPIC_TTS_SAY=tts/say

########################################
# Character (served by memory-worker)
########################################
# Character name and config directory (mounted to /config/characters)
CHARACTER_NAME=TARS
CHARACTER_DIR=/config/characters
CHARACTER_STORE_FILE=character.json
# Character topics
TOPIC_CHARACTER_GET=character/get
TOPIC_CHARACTER_RESULT=character/result
TOPIC_CHARACTER_CURRENT=system/character/current
TOPIC_CHARACTER_UPDATE=character/update

########################################
# LLM Worker (apps/llm-worker)
########################################
# Provider selection: openai | server | local | gemini | dashscope
LLM_PROVIDER=openai
# Model name/id (provider-specific)
LLM_MODEL=gpt-4o-mini
# Generation params
LLM_MAX_TOKENS=256
LLM_TEMPERATURE=0.7
LLM_TOP_P=1.0
LLM_TOP_K=0
LLM_CTX_WINDOW=8192
LLM_DEVICE=cpu
# Provider log level override
LLM_LOG_LEVEL=INFO
# OpenAI-compatible settings (OpenAI, Azure OpenAI, OpenRouter, xAI Grok)
OPENAI_API_KEY=
OPENAI_BASE_URL=
# Response models for optimization (comma-separated patterns)
OPENAI_RESPONSES_MODELS=gpt-4.1*,gpt-4o-mini*,gpt-5*,gpt-5-mini,gpt-5-nano
# Example for xAI Grok (OpenAI-compatible):
# OPENAI_BASE_URL=https://api.x.ai/v1
# OPENAI_API_KEY=sk-...
# Local/Server LLM endpoint
LLM_SERVER_URL=
# Gemini
GEMINI_API_KEY=
GEMINI_BASE_URL=
# DashScope (Qwen)
DASHSCOPE_API_KEY=
DASHSCOPE_BASE_URL=
# RAG toggles for llm-worker
RAG_ENABLED=0
RAG_TOP_K=5
RAG_PROMPT_TEMPLATE=You are TARS. Use the following context to answer the user.\nContext:\n{context}\n\nUser: {user}\nAssistant:

# Enhanced RAG Features (token-aware memory management)
# Token budget for RAG results (prevents context overflow)
RAG_MAX_TOKENS=2000
# Include surrounding conversation context (prev/next entries)
RAG_INCLUDE_CONTEXT=1
# Number of previous/next entries to include around target results
RAG_CONTEXT_WINDOW=1
# Retrieval strategy: hybrid (vector+BM25), recent, or similarity
RAG_STRATEGY=hybrid
# Enable dynamic token-aware prompt building
RAG_DYNAMIC_PROMPTS=1

# LLM model context window size (used for dynamic prompt budgeting)
LLM_CTX_WINDOW=8192
# LLM topics
TOPIC_LLM_REQUEST=llm/request
TOPIC_LLM_RESPONSE=llm/response
TOPIC_LLM_STREAM=llm/stream
TOPIC_LLM_CANCEL=llm/cancel
TOPIC_HEALTH=system/health/llm
TOPIC_MEMORY_QUERY=memory/query
TOPIC_MEMORY_RESULTS=memory/results

# Character (persona) topic
TOPIC_CHARACTER_CURRENT=system/character/current
TOPIC_CHARACTER_GET=character/get
TOPIC_CHARACTER_RESULT=character/result

# Tool calling
TOOL_CALLING_ENABLED=0
TOPIC_TOOLS_REGISTRY=llm/tools/registry
TOPIC_TOOL_CALL_RESULT=llm/tools/result

# Optional: forward streaming chunks to TTS as sentences (now disabled; router bridges LLM->TTS)
LLM_TTS_STREAM=0
TOPIC_TTS_SAY=tts/say
STREAM_MIN_CHARS=60
STREAM_MAX_CHARS=240
STREAM_BOUNDARY_CHARS=.!?;:



########################################
# Enhanced Memory System Features
########################################
# The enhanced memory system provides token-aware memory retrieval
# and dynamic prompt building for better conversation coherence.
#
# Key Features:
# - Token-aware retrieval: Prevents context window overflow
# - Context expansion: Includes surrounding conversation for better flow
# - Multiple retrieval strategies: hybrid, recent, similarity
# - Dynamic prompt building: Intelligent content prioritization
#
# Usage Examples:
#
# Maximum context with token control:
# RAG_ENABLED=1
# RAG_MAX_TOKENS=3000
# RAG_INCLUDE_CONTEXT=1
# RAG_CONTEXT_WINDOW=2
# RAG_STRATEGY=hybrid
# RAG_DYNAMIC_PROMPTS=1
#
# Recent memory focus:
# RAG_ENABLED=1
# RAG_MAX_TOKENS=1000
# RAG_INCLUDE_CONTEXT=0
# RAG_STRATEGY=recent
# RAG_DYNAMIC_PROMPTS=1
#
# Pure similarity search:
# RAG_ENABLED=1
# RAG_MAX_TOKENS=1500
# RAG_INCLUDE_CONTEXT=0
# RAG_STRATEGY=similarity
# RAG_DYNAMIC_PROMPTS=0

########################################
# Movement Service (apps/movement-service)
########################################
# MQTT connection and topic configuration
MOVEMENT_COMMAND_TOPIC=movement/command
MOVEMENT_FRAME_TOPIC=movement/frame
MOVEMENT_STATE_TOPIC=movement/state
MOVEMENT_HEALTH_TOPIC=system/health/movement
# Calibration file path (optional)
MOVEMENT_CALIBRATION_PATH=
# Publishing settings
MOVEMENT_PUBLISH_QOS=1
MOVEMENT_FRAME_BACKOFF_MS=40

########################################
# UI Web (apps/ui-web)
########################################
# Web UI MQTT topic configuration
UI_PARTIAL_TOPIC=stt/partial
UI_FINAL_TOPIC=stt/final
UI_AUDIO_TOPIC=stt/audio_fft
UI_TTS_TOPIC=tts/status
UI_TTS_SAY_TOPIC=tts/say
UI_LLM_STREAM_TOPIC=llm/stream
UI_LLM_RESPONSE_TOPIC=llm/response
UI_MEMORY_QUERY=memory/query
UI_MEMORY_RESULTS=memory/results
UI_HEALTH_TOPIC=system/health/#
# UI_CAMERA_FRAME_TOPIC=camera/frame  # Optional camera support

########################################
# MCP Bridge (apps/mcp-bridge)
########################################
# Workspace and package discovery paths
WORKSPACE_ROOT=/workspace
MCP_LOCAL_PACKAGES_PATH=/workspace/packages
MCP_EXTENSIONS_PATH=/workspace/extensions/mcp-servers
MCP_SERVERS_YAML=/workspace/ops/mcp/mcp.server.yml
# Output configuration
MCP_OUTPUT_DIR=/workspace/config
MCP_CONFIG_FILENAME=mcp-servers.json

########################################
# STT WebSocket Server (server/stt-ws)
########################################
# Faster-Whisper WebSocket server settings
# Whisper model for WS backend
WHISPER_MODEL=small
# Device selection: auto, cpu, cuda (auto recommended)
DEVICE=auto
# Compute type: auto, fp16, int8 (auto recommended)
COMPUTE_TYPE=auto
# Streaming settings
PARTIAL_INTERVAL_MS=300
TAIL_WINDOW_SEC=6.0
# Model storage directory
MODELS_DIR=/models
