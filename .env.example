########################################
# Global / Broker
########################################
# Copy to .env and edit values
MQTT_USER=tars
MQTT_PASS=change_me
MQTT_HOST=127.0.0.1
MQTT_PORT=1883

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

########################################
# STT Worker (apps/stt-worker)
########################################
# Whisper model: tiny, base, small, medium (small is a good default)
WHISPER_MODEL=small
# Backend: whisper | ws | openai
STT_BACKEND=whisper
# WS STT endpoint (used when STT_BACKEND=ws)
WS_URL=ws://127.0.0.1:9000/stt

# OpenAI-compatible STT (used when STT_BACKEND=openai)
OPENAI_API_KEY=
OPENAI_BASE_URL=https://api.openai.com/v1
# Common models: whisper-1, gpt-4o-transcribe, gpt-4o-mini-transcribe (provider-dependent)
OPENAI_STT_MODEL=whisper-1
OPENAI_TIMEOUT_S=30

# Audio & VAD
SAMPLE_RATE=16000
CHUNK_DURATION_MS=30
VAD_AGGRESSIVENESS=2
SILENCE_THRESHOLD_MS=1000

# Half-duplex / publish cadence
POST_PUBLISH_COOLDOWN_MS=400
UNMUTE_GUARD_MS=1000

# Echo suppression
ECHO_SUPPRESS_MATCH=1

# TTS mute window estimation (for avoiding self-echo)
TTS_BASE_MUTE_MS=1200
TTS_PER_CHAR_MS=45
TTS_MAX_MUTE_MS=12000

# Noise floor and quality gates
NOISE_MIN_DURATION_MS=400
NOISE_MIN_RMS=180
NOISE_FLOOR_INIT=180
NOISE_FLOOR_ALPHA=0.05
NOISE_GATE_OFFSET=1.5
NOISE_MIN_ALPHA_RATIO=0.55
NOISE_MIN_LENGTH=3
NOISE_MAX_PUNCT_RATIO=0.35

# Extend dictionary for suppression (comma-separated). Useful for domain terms.
COMMON_WORDS_EXTRA=

# Cough/polite-phrase guardrails
COUGH_ACTIVE_MIN_RATIO=0.25
COUGH_MIN_DURATION_MS=600
COUGH_SUSPICIOUS_PHRASES=thank you,hello,okay,hi
COUGH_MIN_SYLLABLES=2

# Whisper metrics gates
NO_SPEECH_MAX=0.60
AVG_LOGPROB_MIN=-1.20
DICT_MATCH_MIN_RATIO=0.40
REPEAT_COOLDOWN_SEC=8

# Streaming partials
STREAMING_PARTIALS=1
PARTIAL_INTERVAL_MS=600
PARTIAL_MIN_DURATION_MS=500
PARTIAL_MIN_CHARS=4
PARTIAL_MIN_NEW_CHARS=2
PARTIAL_ALPHA_RATIO_MIN=0.5

# Server-side tail window (also used in server/stt-ws)
TAIL_WINDOW_SEC=6.0

# FFT publishing for UI
FFT_PUBLISH=1
FFT_TOPIC=stt/audio_fft
FFT_RATE_HZ=12
FFT_BINS=64
FFT_LOG_SCALE=1

# Optional audio preprocessing (FFmpeg) to trim silence, denoise, and normalize before STT
# Enable to improve transcription robustness on noisy inputs. Default is disabled.
PREPROCESS_ENABLE=0
# Skip preprocessing for very short clips (ms)
PREPROCESS_MIN_MS=600
# Per-utterance FFmpeg timeout (seconds)
PREPROCESS_TIMEOUT_S=6
# FFmpeg filter chain (advanced). Default below is conservative and widely compatible.
# silenceremove trims leading/trailing silence; afftdn lightly denoises; loudnorm normalizes level.
PREPROCESS_FILTERS=silenceremove=start_periods=1:start_silence=2:start_threshold=-35dB:detection=peak,afftdn=nf=-25,loudnorm=I=-18:TP=-2:LRA=11

# Optional suppression quality upgrades (off by default)
SUPPRESS_USE_SYLLAPY=0
SUPPRESS_USE_RAPIDFUZZ=0
ECHO_FUZZ_MIN_RATIO=0.85

########################################
# Router (apps/router)
########################################
# Optional profile tag (not used in code; for your own process labelling)
PROFILE=offline_fast
# Speak a startup message when STT and TTS are both ready
ONLINE_ANNOUNCE=1
ONLINE_ANNOUNCE_TEXT=System online.

# Wake word + live mode (all processed locally)
# Comma/pipe separated wake phrases (case-insensitive). Example: hey tars|ok tars
ROUTER_WAKE_PHRASES=hey tars
# Seconds after a wake word to keep listening for a follow-up request
ROUTER_WAKE_WINDOW_SEC=8
# Short acknowledgement when the wake word is detected (blank to disable)
ROUTER_WAKE_ACK_TEXT=Yes?
# Optional follow-up prompt after the wake ack (blank to disable)
ROUTER_WAKE_REPROMPT_TEXT=
# Start in live mode (routes every utterance without wake word)
ROUTER_LIVE_MODE_DEFAULT=0
# Control phrases to toggle live mode (case-insensitive)
ROUTER_LIVE_MODE_ENTER_PHRASE=start live mode
ROUTER_LIVE_MODE_EXIT_PHRASE=stop live mode
# Spoken confirmations for live mode toggles / state hints
ROUTER_LIVE_MODE_ENTER_ACK=Live mode enabled.
ROUTER_LIVE_MODE_EXIT_ACK=Live mode disabled.
ROUTER_LIVE_MODE_ACTIVE_HINT=Live mode is already active.
ROUTER_LIVE_MODE_INACTIVE_HINT=Live mode is already off.

########################################
# TTS Worker (apps/tts-worker)
########################################
# Piper voice path inside container
PIPER_VOICE=/voices/TARS.onnx
# Streaming synthesis (attempt to reduce time-to-first-audio)
TTS_STREAMING=0
# Pipeline sentence-by-sentence
TTS_PIPELINE=1
# Number of concurrent synth workers when pipelining (only affects non-streaming)
TTS_CONCURRENCY=1
# Use simpleaudio for playback (in-process) instead of paplay/aplay
# Note: simpleaudio not installed by default; see REFACTOR_NOTES.md
TTS_SIMPLEAUDIO=0

# External provider selection (optional)
# Choose text-to-speech engine:
#   piper      = local, offline (default)
#   elevenlabs = hosted ElevenLabs API (requires API key + voice id)
TTS_PROVIDER=piper

# ElevenLabs settings (used when TTS_PROVIDER=elevenlabs)
# Base API URL (usually leave default)
ELEVEN_API_BASE=https://api.elevenlabs.io/v1
# API key for ElevenLabs account (keep secret; do not commit real keys)
ELEVEN_API_KEY=
# Voice ID from your ElevenLabs dashboard (required)
ELEVEN_VOICE_ID=
# Model ID (see ElevenLabs docs). Good default is multilingual v2
ELEVEN_MODEL_ID=eleven_multilingual_v2
# Optimize streaming latency (0..3). Higher can reduce latency at cost of quality.
ELEVEN_OPTIMIZE_STREAMING=0

########################################
# UI Web (apps/ui-web)
########################################
UI_PARTIAL_TOPIC=stt/partial
UI_FINAL_TOPIC=stt/final
UI_TTS_TOPIC=tts/status
UI_AUDIO_TOPIC=stt/audio_fft

########################################
# Pygame UI (apps/ui)
########################################
# Optional: point to TOML config mounted into container
UI_CONFIG=/config/ui.toml
# Env overrides for UI config (optional)
UI_WIDTH=800
UI_HEIGHT=480
UI_FPS=30
UI_NUM_BARS=64
UI_FONT=Arial

########################################
# Memory Worker (apps/memory-worker)
########################################
# Storage
MEMORY_FILE=memory.pickle.gz
RAG_STRATEGY=hybrid
MEMORY_TOP_K=5
# Embedding model (SentenceTransformer)
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
# MQTT topics
TOPIC_MEMORY_QUERY=memory/query
TOPIC_MEMORY_RESULTS=memory/results
# Memory health topic (retained)
TOPIC_MEMORY_HEALTH=system/health/memory

########################################
# Character (served by memory-worker C1)
########################################
# Character name and config directory (mounted to /config/characters)
CHARACTER_NAME=TARS
CHARACTER_DIR=/config/characters
# Character topics
TOPIC_CHARACTER_GET=character/get
TOPIC_CHARACTER_RESULT=character/result
TOPIC_CHARACTER_CURRENT=system/character/current

########################################
# LLM Worker (apps/llm-worker)
########################################
# Provider selection: openai | server | local | gemini | dashscope
LLM_PROVIDER=openai
# Model name/id (provider-specific)
LLM_MODEL=gpt-4o-mini
# Generation params
LLM_MAX_TOKENS=256
LLM_TEMPERATURE=0.7
LLM_TOP_P=1.0
# OpenAI-compatible settings (OpenAI, Azure OpenAI, OpenRouter, xAI Grok)
OPENAI_API_KEY=
OPENAI_BASE_URL=
# Example for xAI Grok (OpenAI-compatible):
# OPENAI_BASE_URL=https://api.x.ai/v1
# OPENAI_API_KEY=sk-...
# Gemini
GEMINI_API_KEY=
GEMINI_BASE_URL=
# DashScope (Qwen)
DASHSCOPE_API_KEY=
DASHSCOPE_BASE_URL=
# RAG toggles for llm-worker
RAG_ENABLED=0
RAG_TOP_K=5
RAG_PROMPT_TEMPLATE=You are TARS. Use the following context to answer the user.\nContext:\n{context}\n\nUser: {user}\nAssistant:
# LLM topics
TOPIC_LLM_REQUEST=llm/request
TOPIC_LLM_RESPONSE=llm/response
TOPIC_LLM_STREAM=llm/stream
TOPIC_LLM_CANCEL=llm/cancel
TOPIC_HEALTH=system/health/llm

########################################
# Router LLM->TTS bridge
########################################
# Router can consume llm/stream and llm/response and publish sentence chunks to tts/say
ROUTER_LLM_TTS_STREAM=1
# Topic names (must match llm-worker and tts-worker)
TOPIC_LLM_STREAM=llm/stream
TOPIC_LLM_RESPONSE=llm/response
TOPIC_LLM_CANCEL=llm/cancel
TOPIC_TTS_SAY=tts/say
# Chunking heuristics for router bridge
STREAM_MIN_CHARS=60
STREAM_MAX_CHARS=240
STREAM_BOUNDARY_CHARS=.!?;:
